{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Instalacion de paquetes necesarios para importar las librerias y ejecutar las celdas para mostrar los graficos"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: nltk in c:\\users\\nacho\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.8.1)\n","Requirement already satisfied: joblib in c:\\users\\nacho\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (1.2.0)\n","Requirement already satisfied: tqdm in c:\\users\\nacho\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (4.65.0)\n","Requirement already satisfied: click in c:\\users\\nacho\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (8.1.3)\n","Requirement already satisfied: regex>=2021.8.3 in c:\\users\\nacho\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (2023.5.5)\n","Requirement already satisfied: colorama in c:\\users\\nacho\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from click->nltk) (0.4.6)\n"]},{"name":"stderr","output_type":"stream","text":["WARNING: You are using pip version 21.2.3; however, version 23.1.2 is available.\n","You should consider upgrading via the 'C:\\Users\\nacho\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n","ERROR: Could not find a version that satisfies the requirement spacyc (from versions: none)\n","ERROR: No matching distribution found for spacyc\n","WARNING: You are using pip version 21.2.3; however, version 23.1.2 is available.\n","You should consider upgrading via the 'C:\\Users\\nacho\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"]},{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: wordcloud in c:\\users\\nacho\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.9.2)\n","Requirement already satisfied: matplotlib in c:\\users\\nacho\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from wordcloud) (3.6.2)\n","Requirement already satisfied: pillow in c:\\users\\nacho\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from wordcloud) (9.3.0)\n","Requirement already satisfied: numpy>=1.6.1 in c:\\users\\nacho\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from wordcloud) (1.22.3)\n","Requirement already satisfied: cycler>=0.10 in c:\\users\\nacho\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->wordcloud) (0.11.0)\n","Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\nacho\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->wordcloud) (3.0.9)\n","Requirement already satisfied: packaging>=20.0 in c:\\users\\nacho\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->wordcloud) (21.3)\n","Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\nacho\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->wordcloud) (1.0.6)\n","Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\nacho\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->wordcloud) (1.4.4)\n","Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\nacho\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->wordcloud) (2.8.2)\n","Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\nacho\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->wordcloud) (4.38.0)\n","Requirement already satisfied: six>=1.5 in c:\\users\\nacho\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.16.0)\n"]},{"name":"stderr","output_type":"stream","text":["WARNING: You are using pip version 21.2.3; however, version 23.1.2 is available.\n","You should consider upgrading via the 'C:\\Users\\nacho\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"]},{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: plotly in c:\\users\\nacho\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (5.14.1)\n","Requirement already satisfied: packaging in c:\\users\\nacho\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from plotly) (21.3)\n","Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\nacho\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from plotly) (8.2.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\nacho\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from packaging->plotly) (3.0.9)\n"]},{"name":"stderr","output_type":"stream","text":["WARNING: You are using pip version 21.2.3; however, version 23.1.2 is available.\n","You should consider upgrading via the 'C:\\Users\\nacho\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"]},{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: matplotlib in c:\\users\\nacho\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.6.2)"]},{"name":"stderr","output_type":"stream","text":["WARNING: You are using pip version 21.2.3; however, version 23.1.2 is available.\n","You should consider upgrading via the 'C:\\Users\\nacho\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"]},{"name":"stdout","output_type":"stream","text":["\n","Requirement already satisfied: packaging>=20.0 in c:\\users\\nacho\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (21.3)\n","Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\nacho\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (4.38.0)\n","Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\nacho\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (3.0.9)\n","Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\nacho\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.4.4)\n","Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\nacho\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (2.8.2)\n","Requirement already satisfied: cycler>=0.10 in c:\\users\\nacho\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (0.11.0)\n","Requirement already satisfied: pillow>=6.2.0 in c:\\users\\nacho\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (9.3.0)\n","Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\nacho\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.0.6)\n","Requirement already satisfied: numpy>=1.19 in c:\\users\\nacho\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.22.3)\n","Requirement already satisfied: six>=1.5 in c:\\users\\nacho\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n","Requirement already satisfied: seaborn in c:\\users\\nacho\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.9.0)\n","Requirement already satisfied: pandas>=0.15.2 in c:\\users\\nacho\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from seaborn) (1.4.2)\n","Requirement already satisfied: numpy>=1.9.3 in c:\\users\\nacho\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from seaborn) (1.22.3)\n","Requirement already satisfied: scipy>=0.14.0 in c:\\users\\nacho\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from seaborn) (1.9.3)\n","Requirement already satisfied: matplotlib>=1.4.3 in c:\\users\\nacho\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from seaborn) (3.6.2)\n","Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\nacho\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=1.4.3->seaborn) (4.38.0)\n","Requirement already satisfied: packaging>=20.0 in c:\\users\\nacho\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=1.4.3->seaborn) (21.3)\n","Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\nacho\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=1.4.3->seaborn) (3.0.9)\n","Requirement already satisfied: pillow>=6.2.0 in c:\\users\\nacho\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=1.4.3->seaborn) (9.3.0)\n","Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\nacho\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=1.4.3->seaborn) (2.8.2)\n","Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\nacho\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=1.4.3->seaborn) (1.0.6)\n","Requirement already satisfied: cycler>=0.10 in c:\\users\\nacho\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=1.4.3->seaborn) (0.11.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\nacho\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=1.4.3->seaborn) (1.4.4)\n","Requirement already satisfied: pytz>=2020.1 in c:\\users\\nacho\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=0.15.2->seaborn) (2022.1)\n","Requirement already satisfied: six>=1.5 in c:\\users\\nacho\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=1.4.3->seaborn) (1.16.0)\n"]},{"name":"stderr","output_type":"stream","text":["WARNING: You are using pip version 21.2.3; however, version 23.1.2 is available.\n","You should consider upgrading via the 'C:\\Users\\nacho\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"]}],"source":["#instalamos los paquetes necesarios para poder importar las librerias\n","!pip install nltk\n","!pip install spacyc\n","!pip install wordcloud\n","!pip install plotly\n","!pip install matplotlib\n","!pip install seaborn\n","!pip install ipython"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Importar las necesidades para el análisis de datos"]},{"cell_type":"code","execution_count":22,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_kg_hide-output":true,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["import re\n","import string\n","import numpy as np\n","import random\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","import plotly\n","import plotly.graph_objs as go\n","import plotly.express as px\n","import plotly.figure_factory as ff\n","from collections import Counter\n","\n","from PIL import Image\n","from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n","\n","import nltk\n","from nltk.corpus import stopwords\n","\n","from tqdm import tqdm\n","import os\n","import spacy\n","from spacy.util import compounding\n","from spacy.util import minibatch\n","\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# Any results you write to the current directory are saved as output."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["**Below is a helper Function which generates random colors which can be used to give different colors to your plots.Feel free to use it**"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"trusted":true},"outputs":[],"source":["def random_colours(number_of_colors):\n","    '''\n","    Simple function for random colours generation.\n","    Input:\n","        number_of_colors - integer value indicating the number of colours which are going to be generated.\n","    Output:\n","        Color in the following format: ['#E86DA4'] .\n","    '''\n","    colors = []\n","    for i in range(number_of_colors):\n","        colors.append(\"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)]))\n","    return colors"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# lectura de datos"]},{"cell_type":"code","execution_count":42,"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_kg_hide-input":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>textID</th>\n","      <th>text</th>\n","      <th>selected_text</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>cb774db0d1</td>\n","      <td>I`d have responded, if I were going</td>\n","      <td>I`d have responded, if I were going</td>\n","      <td>neutral</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>549e992a42</td>\n","      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n","      <td>Sooo SAD</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>088c60f138</td>\n","      <td>my boss is bullying me...</td>\n","      <td>bullying me</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>9642c003ef</td>\n","      <td>what interview! leave me alone</td>\n","      <td>leave me alone</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>358bd9e861</td>\n","      <td>Sons of ****, why couldn`t they put them on t...</td>\n","      <td>Sons of ****,</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>27476</th>\n","      <td>4eac33d1c0</td>\n","      <td>wish we could come see u on Denver  husband l...</td>\n","      <td>d lost</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>27477</th>\n","      <td>4f4c4fc327</td>\n","      <td>I`ve wondered about rake to.  The client has ...</td>\n","      <td>, don`t force</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>27478</th>\n","      <td>f67aae2310</td>\n","      <td>Yay good for both of you. Enjoy the break - y...</td>\n","      <td>Yay good for both of you.</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>27479</th>\n","      <td>ed167662a5</td>\n","      <td>But it was worth it  ****.</td>\n","      <td>But it was worth it  ****.</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>27480</th>\n","      <td>6f7127d9d7</td>\n","      <td>All this flirting going on - The ATG smiles...</td>\n","      <td>All this flirting going on - The ATG smiles. Y...</td>\n","      <td>neutral</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>27480 rows × 4 columns</p>\n","</div>"],"text/plain":["           textID                                               text  \\\n","0      cb774db0d1                I`d have responded, if I were going   \n","1      549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n","2      088c60f138                          my boss is bullying me...   \n","3      9642c003ef                     what interview! leave me alone   \n","4      358bd9e861   Sons of ****, why couldn`t they put them on t...   \n","...           ...                                                ...   \n","27476  4eac33d1c0   wish we could come see u on Denver  husband l...   \n","27477  4f4c4fc327   I`ve wondered about rake to.  The client has ...   \n","27478  f67aae2310   Yay good for both of you. Enjoy the break - y...   \n","27479  ed167662a5                         But it was worth it  ****.   \n","27480  6f7127d9d7     All this flirting going on - The ATG smiles...   \n","\n","                                           selected_text sentiment  \n","0                    I`d have responded, if I were going   neutral  \n","1                                               Sooo SAD  negative  \n","2                                            bullying me  negative  \n","3                                         leave me alone  negative  \n","4                                          Sons of ****,  negative  \n","...                                                  ...       ...  \n","27476                                             d lost  negative  \n","27477                                      , don`t force  negative  \n","27478                          Yay good for both of you.  positive  \n","27479                         But it was worth it  ****.  positive  \n","27480  All this flirting going on - The ATG smiles. Y...   neutral  \n","\n","[27480 rows x 4 columns]"]},"execution_count":42,"metadata":{},"output_type":"execute_result"}],"source":["train = pd.read_csv('train.csv')\n","test = pd.read_csv('test.csv')\n","ss = pd.read_csv('sample_submission.csv')\n","# Eliminar valores nulos\n","train.dropna(inplace=True)\n","train"]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[{"data":{"text/plain":["textID           0\n","text             0\n","selected_text    0\n","sentiment        0\n","dtype: int64"]},"execution_count":43,"metadata":{},"output_type":"execute_result"}],"source":["#comprobar cuantos valores nulos hay en train\n","train.isnull().sum()\n"]},{"cell_type":"code","execution_count":44,"metadata":{"_kg_hide-input":false,"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(27480, 4)\n","(3534, 3)\n"]}],"source":["print(train.shape)\n","print(test.shape)"]},{"cell_type":"code","execution_count":45,"metadata":{"_kg_hide-input":false,"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","Int64Index: 27480 entries, 0 to 27480\n","Data columns (total 4 columns):\n"," #   Column         Non-Null Count  Dtype \n","---  ------         --------------  ----- \n"," 0   textID         27480 non-null  object\n"," 1   text           27480 non-null  object\n"," 2   selected_text  27480 non-null  object\n"," 3   sentiment      27480 non-null  object\n","dtypes: object(4)\n","memory usage: 1.0+ MB\n"]}],"source":["train.info()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["We have one null Value in the train , as the test field for value is NAN we will just remove it"]},{"cell_type":"code","execution_count":46,"metadata":{"trusted":true},"outputs":[],"source":["train.dropna(inplace=True)"]},{"cell_type":"code","execution_count":47,"metadata":{"_kg_hide-input":false,"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 3534 entries, 0 to 3533\n","Data columns (total 3 columns):\n"," #   Column     Non-Null Count  Dtype \n","---  ------     --------------  ----- \n"," 0   textID     3534 non-null   object\n"," 1   text       3534 non-null   object\n"," 2   sentiment  3534 non-null   object\n","dtypes: object(3)\n","memory usage: 83.0+ KB\n"]}],"source":["test.info()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["There are no null Values in the test set"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# EDA"]},{"cell_type":"code","execution_count":48,"metadata":{"_kg_hide-input":false,"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>textID</th>\n","      <th>text</th>\n","      <th>selected_text</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>cb774db0d1</td>\n","      <td>I`d have responded, if I were going</td>\n","      <td>I`d have responded, if I were going</td>\n","      <td>neutral</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>549e992a42</td>\n","      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n","      <td>Sooo SAD</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>088c60f138</td>\n","      <td>my boss is bullying me...</td>\n","      <td>bullying me</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>9642c003ef</td>\n","      <td>what interview! leave me alone</td>\n","      <td>leave me alone</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>358bd9e861</td>\n","      <td>Sons of ****, why couldn`t they put them on t...</td>\n","      <td>Sons of ****,</td>\n","      <td>negative</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       textID                                               text  \\\n","0  cb774db0d1                I`d have responded, if I were going   \n","1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n","2  088c60f138                          my boss is bullying me...   \n","3  9642c003ef                     what interview! leave me alone   \n","4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n","\n","                         selected_text sentiment  \n","0  I`d have responded, if I were going   neutral  \n","1                             Sooo SAD  negative  \n","2                          bullying me  negative  \n","3                       leave me alone  negative  \n","4                        Sons of ****,  negative  "]},"execution_count":48,"metadata":{},"output_type":"execute_result"}],"source":["train.head()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Selected_text is a subset of text "]},{"cell_type":"code","execution_count":49,"metadata":{"_kg_hide-input":false,"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>textID</th>\n","      <th>text</th>\n","      <th>selected_text</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>27480</td>\n","      <td>27480</td>\n","      <td>27480</td>\n","      <td>27480</td>\n","    </tr>\n","    <tr>\n","      <th>unique</th>\n","      <td>27480</td>\n","      <td>27480</td>\n","      <td>22463</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>top</th>\n","      <td>cb774db0d1</td>\n","      <td>I`d have responded, if I were going</td>\n","      <td>good</td>\n","      <td>neutral</td>\n","    </tr>\n","    <tr>\n","      <th>freq</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>199</td>\n","      <td>11117</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["            textID                                  text selected_text  \\\n","count        27480                                 27480         27480   \n","unique       27480                                 27480         22463   \n","top     cb774db0d1   I`d have responded, if I were going          good   \n","freq             1                                     1           199   \n","\n","       sentiment  \n","count      27480  \n","unique         3  \n","top      neutral  \n","freq       11117  "]},"execution_count":49,"metadata":{},"output_type":"execute_result"}],"source":["train.describe()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Lets look at the distribution of tweets in the train set"]},{"cell_type":"code","execution_count":50,"metadata":{"_kg_hide-input":true,"trusted":true},"outputs":[{"data":{"text/html":["<style type=\"text/css\">\n","#T_e683c_row0_col1 {\n","  background-color: #3f007d;\n","  color: #f1f1f1;\n","}\n","#T_e683c_row1_col1 {\n","  background-color: #dcdcec;\n","  color: #000000;\n","}\n","#T_e683c_row2_col1 {\n","  background-color: #fcfbfd;\n","  color: #000000;\n","}\n","</style>\n","<table id=\"T_e683c\">\n","  <thead>\n","    <tr>\n","      <th class=\"blank level0\" >&nbsp;</th>\n","      <th id=\"T_e683c_level0_col0\" class=\"col_heading level0 col0\" >sentiment</th>\n","      <th id=\"T_e683c_level0_col1\" class=\"col_heading level0 col1\" >text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th id=\"T_e683c_level0_row0\" class=\"row_heading level0 row0\" >1</th>\n","      <td id=\"T_e683c_row0_col0\" class=\"data row0 col0\" >neutral</td>\n","      <td id=\"T_e683c_row0_col1\" class=\"data row0 col1\" >11117</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_e683c_level0_row1\" class=\"row_heading level0 row1\" >2</th>\n","      <td id=\"T_e683c_row1_col0\" class=\"data row1 col0\" >positive</td>\n","      <td id=\"T_e683c_row1_col1\" class=\"data row1 col1\" >8582</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_e683c_level0_row2\" class=\"row_heading level0 row2\" >0</th>\n","      <td id=\"T_e683c_row2_col0\" class=\"data row2 col0\" >negative</td>\n","      <td id=\"T_e683c_row2_col1\" class=\"data row2 col1\" >7781</td>\n","    </tr>\n","  </tbody>\n","</table>\n"],"text/plain":["<pandas.io.formats.style.Styler at 0x1da7940b400>"]},"execution_count":50,"metadata":{},"output_type":"execute_result"}],"source":["temp = train.groupby('sentiment').count()['text'].reset_index().sort_values(by='text',ascending=False)\n","temp.style.background_gradient(cmap='Purples')"]},{"cell_type":"code","execution_count":51,"metadata":{"_kg_hide-input":true,"trusted":true},"outputs":[{"data":{"text/plain":["<AxesSubplot: xlabel='sentiment', ylabel='count'>"]},"execution_count":51,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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","text/plain":["<Figure size 1200x600 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["plt.figure(figsize=(12,6))\n","sns.countplot(x='sentiment',data=train)"]},{"cell_type":"code","execution_count":52,"metadata":{},"outputs":[{"ename":"ValueError","evalue":"Mime type rendering requires nbformat>=4.2.0 but it is not installed","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[1;32mc:\\Users\\nacho\\Desktop\\examen final eda1\\twitter-sentiment-extaction-analysis-eda-and-model.ipynb Cell 22\u001b[0m in \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nacho/Desktop/examen%20final%20eda1/twitter-sentiment-extaction-analysis-eda-and-model.ipynb#Y223sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mplotly\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgraph_objs\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mgo\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nacho/Desktop/examen%20final%20eda1/twitter-sentiment-extaction-analysis-eda-and-model.ipynb#Y223sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m fig \u001b[39m=\u001b[39m go\u001b[39m.\u001b[39mFigure(go\u001b[39m.\u001b[39mFunnel(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nacho/Desktop/examen%20final%20eda1/twitter-sentiment-extaction-analysis-eda-and-model.ipynb#Y223sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     y\u001b[39m=\u001b[39mtemp\u001b[39m.\u001b[39msentiment,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nacho/Desktop/examen%20final%20eda1/twitter-sentiment-extaction-analysis-eda-and-model.ipynb#Y223sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     x\u001b[39m=\u001b[39mtemp\u001b[39m.\u001b[39mtext,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nacho/Desktop/examen%20final%20eda1/twitter-sentiment-extaction-analysis-eda-and-model.ipynb#Y223sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     textinfo\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mvalue+percent initial\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nacho/Desktop/examen%20final%20eda1/twitter-sentiment-extaction-analysis-eda-and-model.ipynb#Y223sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     marker\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mcolor\u001b[39m\u001b[39m\"\u001b[39m: [\u001b[39m\"\u001b[39m\u001b[39m#FF9F43\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m#FF6A3D\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m#FF3838\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m#FF004D\u001b[39m\u001b[39m\"\u001b[39m]}\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nacho/Desktop/examen%20final%20eda1/twitter-sentiment-extaction-analysis-eda-and-model.ipynb#Y223sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m ))\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/nacho/Desktop/examen%20final%20eda1/twitter-sentiment-extaction-analysis-eda-and-model.ipynb#Y223sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m fig\u001b[39m.\u001b[39;49mshow()\n","File \u001b[1;32mc:\\Users\\nacho\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\plotly\\basedatatypes.py:3390\u001b[0m, in \u001b[0;36mBaseFigure.show\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3357\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   3358\u001b[0m \u001b[39mShow a figure using either the default renderer(s) or the renderer(s)\u001b[39;00m\n\u001b[0;32m   3359\u001b[0m \u001b[39mspecified by the renderer argument\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3386\u001b[0m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   3387\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   3388\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mplotly\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mio\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpio\u001b[39;00m\n\u001b[1;32m-> 3390\u001b[0m \u001b[39mreturn\u001b[39;00m pio\u001b[39m.\u001b[39mshow(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n","File \u001b[1;32mc:\\Users\\nacho\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\plotly\\io\\_renderers.py:396\u001b[0m, in \u001b[0;36mshow\u001b[1;34m(fig, renderer, validate, **kwargs)\u001b[0m\n\u001b[0;32m    391\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    392\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mMime type rendering requires ipython but it is not installed\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    393\u001b[0m         )\n\u001b[0;32m    395\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m nbformat \u001b[39mor\u001b[39;00m Version(nbformat\u001b[39m.\u001b[39m__version__) \u001b[39m<\u001b[39m Version(\u001b[39m\"\u001b[39m\u001b[39m4.2.0\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 396\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    397\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mMime type rendering requires nbformat>=4.2.0 but it is not installed\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    398\u001b[0m         )\n\u001b[0;32m    400\u001b[0m     ipython_display\u001b[39m.\u001b[39mdisplay(bundle, raw\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    402\u001b[0m \u001b[39m# external renderers\u001b[39;00m\n","\u001b[1;31mValueError\u001b[0m: Mime type rendering requires nbformat>=4.2.0 but it is not installed"]}],"source":["#Vamos a seleccionar train como conjunto de datos a analizar, para ello debe analizar la distribución de tweets en el conjunto y Dibujar un gráfico de embudo para una mejor visualización.\n","#Dibujar un gráfico de embudo para una mejor visualización.\n","import plotly.graph_objs as go\n","\n","fig = go.Figure(go.Funnel(\n","    y=temp.sentiment,\n","    x=temp.text,\n","    textinfo=\"value+percent initial\",\n","    marker={\"color\": [\"#FF9F43\", \"#FF6A3D\", \"#FF3838\", \"#FF004D\"]}\n","))\n","\n","fig.show()\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Let's draw a Funnel-Chart for better visualization"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"trusted":true},"outputs":[{"ename":"ValueError","evalue":"Mime type rendering requires nbformat>=4.2.0 but it is not installed","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[1;32mc:\\Users\\nacho\\Desktop\\examen final eda1\\twitter-sentiment-extaction-analysis-eda-and-model.ipynb Cell 24\u001b[0m in \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nacho/Desktop/examen%20final%20eda1/twitter-sentiment-extaction-analysis-eda-and-model.ipynb#X31sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m fig \u001b[39m=\u001b[39m go\u001b[39m.\u001b[39mFigure(go\u001b[39m.\u001b[39mFunnelarea(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nacho/Desktop/examen%20final%20eda1/twitter-sentiment-extaction-analysis-eda-and-model.ipynb#X31sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     text \u001b[39m=\u001b[39mtemp\u001b[39m.\u001b[39msentiment,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nacho/Desktop/examen%20final%20eda1/twitter-sentiment-extaction-analysis-eda-and-model.ipynb#X31sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     values \u001b[39m=\u001b[39m temp\u001b[39m.\u001b[39mtext,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nacho/Desktop/examen%20final%20eda1/twitter-sentiment-extaction-analysis-eda-and-model.ipynb#X31sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     title \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mposition\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mtop center\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mFunnel-Chart of Sentiment Distribution\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nacho/Desktop/examen%20final%20eda1/twitter-sentiment-extaction-analysis-eda-and-model.ipynb#X31sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     ))\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/nacho/Desktop/examen%20final%20eda1/twitter-sentiment-extaction-analysis-eda-and-model.ipynb#X31sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m fig\u001b[39m.\u001b[39;49mshow()\n","File \u001b[1;32mc:\\Users\\nacho\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\plotly\\basedatatypes.py:3390\u001b[0m, in \u001b[0;36mBaseFigure.show\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3357\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   3358\u001b[0m \u001b[39mShow a figure using either the default renderer(s) or the renderer(s)\u001b[39;00m\n\u001b[0;32m   3359\u001b[0m \u001b[39mspecified by the renderer argument\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3386\u001b[0m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   3387\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   3388\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mplotly\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mio\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpio\u001b[39;00m\n\u001b[1;32m-> 3390\u001b[0m \u001b[39mreturn\u001b[39;00m pio\u001b[39m.\u001b[39mshow(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n","File \u001b[1;32mc:\\Users\\nacho\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\plotly\\io\\_renderers.py:396\u001b[0m, in \u001b[0;36mshow\u001b[1;34m(fig, renderer, validate, **kwargs)\u001b[0m\n\u001b[0;32m    391\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    392\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mMime type rendering requires ipython but it is not installed\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    393\u001b[0m         )\n\u001b[0;32m    395\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m nbformat \u001b[39mor\u001b[39;00m Version(nbformat\u001b[39m.\u001b[39m__version__) \u001b[39m<\u001b[39m Version(\u001b[39m\"\u001b[39m\u001b[39m4.2.0\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 396\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    397\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mMime type rendering requires nbformat>=4.2.0 but it is not installed\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    398\u001b[0m         )\n\u001b[0;32m    400\u001b[0m     ipython_display\u001b[39m.\u001b[39mdisplay(bundle, raw\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    402\u001b[0m \u001b[39m# external renderers\u001b[39;00m\n","\u001b[1;31mValueError\u001b[0m: Mime type rendering requires nbformat>=4.2.0 but it is not installed"]}],"source":["fig = go.Figure(go.Funnelarea(\n","    text =temp.sentiment,\n","    values = temp.text,\n","    title = {\"position\": \"top center\", \"text\": \"Funnel-Chart of Sentiment Distribution\"}\n","    ))\n","fig.show()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## What do we currently Know About our Data:\n","\n","Before starting let's look at some things that we already know about the data and will help us in gaining more new insights:\n","* We Know that selected_text is a subset of text\n","* We know that selected_text contains only one segment of text,i.e,It does not jump between two sentences.For Eg:- If text is 'Spent the entire morning in a meeting w/ a vendor, and my boss was not happy w/ them. Lots of fun.  I had other plans for my morning' The selected text can be 'my boss was not happy w/ them. Lots of fun' or 'Lots of fun' but cannot be 'Morning,vendor and my boss,\n","* Thanks to this discussion:https://www.kaggle.com/c/tweet-sentiment-extraction/discussion/138520 We know that neutral tweets have a jaccard similarity of 97 percent between text and selected_text\n","* Also as discussed here https://www.kaggle.com/c/tweet-sentiment-extraction/discussion/138272 ,there are rows where selected_text starts from between the words and thus selected_texts dont always make sense and since we do not know whether the output of test set contain these descrepancies or not ,we are not sure that preprocessing and removing punctuations would be a good idea or not"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Generating Meta-Features"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["**In the previous versions of this notebook,I used Number of words in selected text and main text ,Length of words in text and selected as main meta features,but in the context of this competition where we have to predict selected_text which is a subset of text, more useful features to generate would be** :-\n","* Difference In Number Of words of Selected_text and Text\n","* Jaccard Similarity Scores between text and Selected_text\n","\n","Thus it will not be useful for us to generate features we used before as they are of no importance here\n","\n","For what who don't know what Jaccard Similarity is : https://www.geeksforgeeks.org/find-the-jaccard-index-and-jaccard-distance-between-the-two-given-sets/"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"trusted":true},"outputs":[],"source":["def jaccard(str1, str2): \n","    a = set(str1.lower().split()) \n","    b = set(str2.lower().split())\n","    c = a.intersection(b)\n","    return float(len(c)) / (len(a) + len(b) - len(c))"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"trusted":true},"outputs":[],"source":["results_jaccard=[]\n","\n","for ind,row in train.iterrows():\n","    sentence1 = row.text\n","    sentence2 = row.selected_text\n","\n","    jaccard_score = jaccard(sentence1,sentence2)\n","    results_jaccard.append([sentence1,sentence2,jaccard_score])"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"trusted":true},"outputs":[],"source":["jaccard = pd.DataFrame(results_jaccard,columns=[\"text\",\"selected_text\",\"jaccard_score\"])\n","train = train.merge(jaccard,how='outer')"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"trusted":true},"outputs":[],"source":["train['Num_words_ST'] = train['selected_text'].apply(lambda x:len(str(x).split())) #Number Of words in Selected Text\n","train['Num_word_text'] = train['text'].apply(lambda x:len(str(x).split())) #Number Of words in main text\n","train['difference_in_words'] = train['Num_word_text'] - train['Num_words_ST'] #Difference in Number of words text and Selected Text"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train.head()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Let's look at the distribution of Meta-Features"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"trusted":true},"outputs":[],"source":["hist_data = [train['Num_words_ST'],train['Num_word_text']]\n","\n","group_labels = ['Selected_Text', 'Text']\n","\n","# Create distplot with custom bin_size\n","fig = ff.create_distplot(hist_data, group_labels,show_curve=False)\n","fig.update_layout(title_text='Distribution of Number Of words')\n","fig.update_layout(\n","    autosize=False,\n","    width=900,\n","    height=700,\n","    paper_bgcolor=\"LightSteelBlue\",\n",")\n","fig.show()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["* The number of words plot is really interesting ,the tweets having number of words greater than 25 are very less and thus the number of words distribution plot is right skewed"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["plt.figure(figsize=(12,6))\n","p1=sns.kdeplot(train['Num_words_ST'], shade=True, color=\"r\").set_title('Kernel Distribution of Number Of words')\n","p1=sns.kdeplot(train['Num_word_text'], shade=True, color=\"b\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["**Now It will be more interesting to see the differnce in number of words and jaccard_scores across different Sentiments**"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"trusted":true},"outputs":[],"source":["plt.figure(figsize=(12,6))\n","p1=sns.kdeplot(train[train['sentiment']=='positive']['difference_in_words'], shade=True, color=\"b\").set_title('Kernel Distribution of Difference in Number Of words')\n","p2=sns.kdeplot(train[train['sentiment']=='negative']['difference_in_words'], shade=True, color=\"r\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["plt.figure(figsize=(12,6))\n","sns.distplot(train[train['sentiment']=='neutral']['difference_in_words'],kde=False)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["I was not able to plot kde plot for neutral tweets because most of the values for difference in number of words were zero. We can see it clearly now ,if we had used the feature in the starting we would have known that text and selected text are mostly the same for neutral tweets,thus its always important to keep the end goal in mind while performing EDA"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["plt.figure(figsize=(12,6))\n","p1=sns.kdeplot(train[train['sentiment']=='positive']['jaccard_score'], shade=True, color=\"b\").set_title('KDE of Jaccard Scores across different Sentiments')\n","p2=sns.kdeplot(train[train['sentiment']=='negative']['jaccard_score'], shade=True, color=\"r\")\n","plt.legend(labels=['positive','negative'])"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["I was not able to plot kde of jaccard_scores of neutral tweets for the same reason,thus I will plot a distribution plot"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["plt.figure(figsize=(12,6))\n","sns.distplot(train[train['sentiment']=='neutral']['jaccard_score'],kde=False)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["We can see some interesting trends here:\n","* Positive and negative tweets have high kurtosis and thus values are concentrated in two regions narrow and high density \n","* Neutral tweets have a low kurtosis value and their is bump in density near values of 1\n","\n","For those who don't know :\n","* Kurtosis is the measure of how peaked a distribution is and how much spread it is around that peak\n","* Skewness measures how much a curve deviates from a normal distribution"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Conclusion Of EDA\n","\n","* We can see from the jaccard score plot that there is peak for negative and positive plot around score of 1 .That means there is a cluster of tweets where there is a high similarity between text and selected texts ,if we can find those clusters then we can predict text for selected texts for those tweets irrespective of segment\n","\n","Let's see if we can find those clusters,one interesting idea would be to check tweets which have number of words lesss than 3 in text, because there the text might be completely used as text"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["k = train[train['Num_word_text']<=2]"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["k.groupby('sentiment').mean()['jaccard_score']"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["We can see that there is similarity between text and selected text .Let's have closer look"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["k[k['sentiment']=='positive']"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Thus its clear that most of the times , text is used as selected text.We can improve this by preprocessing the text which have word length less than 3.We will remember this information and use it in model building"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Cleaning the Corpus\n","Now Before We Dive into extracting information out of words in text and selected text,let's first clean the data"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def clean_text(text):\n","    '''Make text lowercase, remove text in square brackets,remove links,remove punctuation\n","    and remove words containing numbers.'''\n","    text = str(text).lower()\n","    text = re.sub('\\[.*?\\]', '', text)\n","    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n","    text = re.sub('<.*?>+', '', text)\n","    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n","    text = re.sub('\\n', '', text)\n","    text = re.sub('\\w*\\d\\w*', '', text)\n","    return text"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train['text'] = train['text'].apply(lambda x:clean_text(x))\n","train['selected_text'] = train['selected_text'].apply(lambda x:clean_text(x))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train.head()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Most Common words in our Target-Selected Text"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"trusted":true},"outputs":[],"source":["train['temp_list'] = train['selected_text'].apply(lambda x:str(x).split())\n","top = Counter([item for sublist in train['temp_list'] for item in sublist])\n","temp = pd.DataFrame(top.most_common(20))\n","temp.columns = ['Common_words','count']\n","temp.style.background_gradient(cmap='Blues')"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"trusted":true},"outputs":[],"source":["fig = px.bar(temp, x=\"count\", y=\"Common_words\", title='Commmon Words in Selected Text', orientation='h', \n","             width=700, height=700,color='Common_words')\n","fig.show()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["OOPS!While we cleaned our dataset we didnt remove the stop words and hence we can see the most coomon word is 'to' . Let's try again after removing the stopwords"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"trusted":true},"outputs":[],"source":["def remove_stopword(x):\n","    return [y for y in x if y not in stopwords.words('english')]\n","train['temp_list'] = train['temp_list'].apply(lambda x:remove_stopword(x))"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"trusted":true},"outputs":[],"source":["top = Counter([item for sublist in train['temp_list'] for item in sublist])\n","temp = pd.DataFrame(top.most_common(20))\n","temp = temp.iloc[1:,:]\n","temp.columns = ['Common_words','count']\n","temp.style.background_gradient(cmap='Purples')"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"trusted":true},"outputs":[],"source":["fig = px.treemap(temp, path=['Common_words'], values='count',title='Tree of Most Common Words')\n","fig.show()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Most Common words in Text\n","\n","Let's also look at the most common words in Text"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"trusted":true},"outputs":[],"source":["train['temp_list1'] = train['text'].apply(lambda x:str(x).split()) #List of words in every row for text\n","train['temp_list1'] = train['temp_list1'].apply(lambda x:remove_stopword(x)) #Removing Stopwords"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"trusted":true},"outputs":[],"source":["top = Counter([item for sublist in train['temp_list1'] for item in sublist])\n","temp = pd.DataFrame(top.most_common(25))\n","temp = temp.iloc[1:,:]\n","temp.columns = ['Common_words','count']\n","temp.style.background_gradient(cmap='Blues')"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["So the first two common word was I'm so I removed it and took data from second row"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"trusted":true},"outputs":[],"source":["fig = px.bar(temp, x=\"count\", y=\"Common_words\", title='Commmon Words in Text', orientation='h', \n","             width=700, height=700,color='Common_words')\n","fig.show()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["SO we can see the Most common words in Selected text and Text are almost the same,which was obvious"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Most common words Sentiments Wise\n","\n","Let's look at the most common words in different sentiments"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["Positive_sent = train[train['sentiment']=='positive']\n","Negative_sent = train[train['sentiment']=='negative']\n","Neutral_sent = train[train['sentiment']=='neutral']"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"trusted":true},"outputs":[],"source":["#MosT common positive words\n","top = Counter([item for sublist in Positive_sent['temp_list'] for item in sublist])\n","temp_positive = pd.DataFrame(top.most_common(20))\n","temp_positive.columns = ['Common_words','count']\n","temp_positive.style.background_gradient(cmap='Greens')"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"trusted":true},"outputs":[],"source":["fig = px.bar(temp_positive, x=\"count\", y=\"Common_words\", title='Most Commmon Positive Words', orientation='h', \n","             width=700, height=700,color='Common_words')\n","fig.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"trusted":true},"outputs":[],"source":["#MosT common negative words\n","top = Counter([item for sublist in Negative_sent['temp_list'] for item in sublist])\n","temp_negative = pd.DataFrame(top.most_common(20))\n","temp_negative = temp_negative.iloc[1:,:]\n","temp_negative.columns = ['Common_words','count']\n","temp_negative.style.background_gradient(cmap='Reds')"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"trusted":true},"outputs":[],"source":["fig = px.treemap(temp_negative, path=['Common_words'], values='count',title='Tree Of Most Common Negative Words')\n","fig.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"trusted":true},"outputs":[],"source":["#MosT common Neutral words\n","top = Counter([item for sublist in Neutral_sent['temp_list'] for item in sublist])\n","temp_neutral = pd.DataFrame(top.most_common(20))\n","temp_neutral = temp_neutral.loc[1:,:]\n","temp_neutral.columns = ['Common_words','count']\n","temp_neutral.style.background_gradient(cmap='Reds')"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"trusted":true},"outputs":[],"source":["fig = px.bar(temp_neutral, x=\"count\", y=\"Common_words\", title='Most Commmon Neutral Words', orientation='h', \n","             width=700, height=700,color='Common_words')\n","fig.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"trusted":true},"outputs":[],"source":["fig = px.treemap(temp_neutral, path=['Common_words'], values='count',title='Tree Of Most Common Neutral Words')\n","fig.show()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["* We can see words like get,go,dont,got,u,cant,lol,like are common in all three segments . That's interesting because words like dont and cant are more of negative nature and words like lol are more of positive nature.Does this mean our data is incorrectly labelled , we will have more insights on this after N-gram analysis\n","* It will be interesting to see the word unique to different sentiments"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Let's Look at Unique Words in each Segment\n","\n","We will look at unique words in each segment in the Following Order:\n","* Positive\n","* Negative\n","* Neutral"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["raw_text = [word for word_list in train['temp_list1'] for word in word_list]"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"trusted":true},"outputs":[],"source":["def words_unique(sentiment,numwords,raw_words):\n","    '''\n","    Input:\n","        segment - Segment category (ex. 'Neutral');\n","        numwords - how many specific words do you want to see in the final result; \n","        raw_words - list  for item in train_data[train_data.segments == segments]['temp_list1']:\n","    Output: \n","        dataframe giving information about the name of the specific ingredient and how many times it occurs in the chosen cuisine (in descending order based on their counts)..\n","\n","    '''\n","    allother = []\n","    for item in train[train.sentiment != sentiment]['temp_list1']:\n","        for word in item:\n","            allother .append(word)\n","    allother  = list(set(allother ))\n","    \n","    specificnonly = [x for x in raw_text if x not in allother]\n","    \n","    mycounter = Counter()\n","    \n","    for item in train[train.sentiment == sentiment]['temp_list1']:\n","        for word in item:\n","            mycounter[word] += 1\n","    keep = list(specificnonly)\n","    \n","    for word in list(mycounter):\n","        if word not in keep:\n","            del mycounter[word]\n","    \n","    Unique_words = pd.DataFrame(mycounter.most_common(numwords), columns = ['words','count'])\n","    \n","    return Unique_words"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Positive Tweets"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["Unique_Positive= words_unique('positive', 20, raw_text)\n","print(\"The top 20 unique words in Positive Tweets are:\")\n","Unique_Positive.style.background_gradient(cmap='Greens')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["fig = px.treemap(Unique_Positive, path=['words'], values='count',title='Tree Of Unique Positive Words')\n","fig.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"trusted":true},"outputs":[],"source":["from palettable.colorbrewer.qualitative import Pastel1_7\n","plt.figure(figsize=(16,10))\n","my_circle=plt.Circle((0,0), 0.7, color='white')\n","plt.pie(Unique_Positive['count'], labels=Unique_Positive.words, colors=Pastel1_7.hex_colors)\n","p=plt.gcf()\n","p.gca().add_artist(my_circle)\n","plt.title('DoNut Plot Of Unique Positive Words')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["Unique_Negative= words_unique('negative', 10, raw_text)\n","print(\"The top 10 unique words in Negative Tweets are:\")\n","Unique_Negative.style.background_gradient(cmap='Reds')"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"trusted":true},"outputs":[],"source":["from palettable.colorbrewer.qualitative import Pastel1_7\n","plt.figure(figsize=(16,10))\n","my_circle=plt.Circle((0,0), 0.7, color='white')\n","plt.rcParams['text.color'] = 'black'\n","plt.pie(Unique_Negative['count'], labels=Unique_Negative.words, colors=Pastel1_7.hex_colors)\n","p=plt.gcf()\n","p.gca().add_artist(my_circle)\n","plt.title('DoNut Plot Of Unique Negative Words')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["Unique_Neutral= words_unique('neutral', 10, raw_text)\n","print(\"The top 10 unique words in Neutral Tweets are:\")\n","Unique_Neutral.style.background_gradient(cmap='Oranges')"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"trusted":true},"outputs":[],"source":["from palettable.colorbrewer.qualitative import Pastel1_7\n","plt.figure(figsize=(16,10))\n","my_circle=plt.Circle((0,0), 0.7, color='white')\n","plt.pie(Unique_Neutral['count'], labels=Unique_Neutral.words, colors=Pastel1_7.hex_colors)\n","p=plt.gcf()\n","p.gca().add_artist(my_circle)\n","plt.title('DoNut Plot Of Unique Neutral Words')\n","plt.show()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["**By Looking at the Unique Words of each sentiment,we now have much more clarity about the data,these unique words are very strong determiners of Sentiment of tweets**"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## It's Time For WordClouds\n","\n","We will be building wordclouds in the following order:\n","\n","* WordCloud of Neutral Tweets\n","* WordCloud of Positive Tweets\n","* WordCloud of Negative Tweets\n"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"trusted":true},"outputs":[],"source":["def plot_wordcloud(text, mask=None, max_words=200, max_font_size=100, figure_size=(24.0,16.0), color = 'white',\n","                   title = None, title_size=40, image_color=False):\n","    stopwords = set(STOPWORDS)\n","    more_stopwords = {'u', \"im\"}\n","    stopwords = stopwords.union(more_stopwords)\n","\n","    wordcloud = WordCloud(background_color=color,\n","                    stopwords = stopwords,\n","                    max_words = max_words,\n","                    max_font_size = max_font_size, \n","                    random_state = 42,\n","                    width=400, \n","                    height=200,\n","                    mask = mask)\n","    wordcloud.generate(str(text))\n","    \n","    plt.figure(figsize=figure_size)\n","    if image_color:\n","        image_colors = ImageColorGenerator(mask);\n","        plt.imshow(wordcloud.recolor(color_func=image_colors), interpolation=\"bilinear\");\n","        plt.title(title, fontdict={'size': title_size,  \n","                                  'verticalalignment': 'bottom'})\n","    else:\n","        plt.imshow(wordcloud);\n","        plt.title(title, fontdict={'size': title_size, 'color': 'black', \n","                                  'verticalalignment': 'bottom'})\n","    plt.axis('off');\n","    plt.tight_layout()  \n","d = '/kaggle/input/masks-for-wordclouds/'"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["I have added more words like im , u (that we say were there in the most common words,disturbing our analysis) as stopwords"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["#### WORDCLOUD OF NEUTRAL TWEETS\n","\n","We Have already visualized our Most Common Negative words ,but Wordclouds Provide us much more clarity"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"trusted":true},"outputs":[],"source":["pos_mask = np.array(Image.open(d+ 'twitter_mask.png'))\n","plot_wordcloud(Neutral_sent.text,mask=pos_mask,color='white',max_font_size=100,title_size=30,title=\"WordCloud of Neutral Tweets\")"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"trusted":true},"outputs":[],"source":["plot_wordcloud(Positive_sent.text,mask=pos_mask,title=\"Word Cloud Of Positive tweets\",title_size=30)"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"trusted":true},"outputs":[],"source":["plot_wordcloud(Negative_sent.text,mask=pos_mask,title=\"Word Cloud of Negative Tweets\",color='white',title_size=30)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Modelling\n","\n","This is the first kaggle competition , I am participating in and this might be the case with lot of us.Due to the unique structure of the problem statement, it is hard for any first timer or a competitions noob to answer the question\"Which Model to Use\"?.My initial thoughts was this competition is not for me and I am done here,but then I remembered something, I was at the KaggleDays Meetup Delhi this year and I had this wonderful oppurtunity to meet Grandmaster Abhishek Thakur and during the Q&A session I asked him that kaggle competitions are so diverse ,unique ,require a lot of background knowledge and thus is scary to participate, to which he replied and I quote \"Scary Yes!But so is walking into a dark room,you will never learn if you won't participate\".\n","\n","So here I am fighting my way through this competition and trying to learn different things and I urge everyone to do the same , I might not be so well established to give advices but I really wanted to share that story to motivate people.\n","\n","After going through the discussion forums,taking advices from experts and watching Abhishek Sir's tutorial last night ,this problem can be modelled as following:-\n","* Named Entity Recognition\n","* Q&A Problem\n","* I also found a simple approach shared by Nick in his beautiful kernel where he has the concept of Gini Impurity to give weights to words present in tweets and then predicting using the weight of those words : https://www.kaggle.com/nkoprowicz/a-simple-solution-using-only-word-counts/notebook .Do check it out.\n","* Other Modelling Ideas :- https://www.kaggle.com/c/tweet-sentiment-extraction/discussion/139803 --> Here is a very Nice Idea\n","* Another useful Idea :- https://www.kaggle.com/c/tweet-sentiment-extraction/discussion/139335\n","\n","Resources :\n","* For Modelling Problem as NER : https://www.kaggle.com/rohitsingh9990/ner-training-using-spacy-0-628-lb\n","* For Modelling Problem AS Q&A : https://www.kaggle.com/jonathanbesomi/question-answering-starter-pack ---> This is a complete Guide and From scratch"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## 1)Modelling the Problem as NER\n","\n","Named Entity Recognition (NER) is a standard NLP problem which involves spotting named entities (people, places, organizations etc.) from a chunk of text, and classifying them into a predefined set of categories.\n","For understanding NER here is very good article : https://towardsdatascience.com/named-entity-recognition-with-nltk-and-spacy-8c4a7d88e7da\n","\n","We will be using spacy for creating our own customised NER model or models (seperate for each Sentiment).The motivation for this approach is off course the kernel shared by Rohit Singh,so if you find his kernel useful please upvote it.\n","\n","What will be different with my solution:\n","* I will use text as selected_text for all neutral tweets due to their high jaccard similarity\n","* Also I will use text as selected_text for all tweets having number of words less than 3 in text as explained before\n","* I will train two different models for Positive and Negtive tweets\n","* I will not preprocess the data because the selected text contains raw text"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df_train = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/train.csv')\n","df_test = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/test.csv')\n","df_submission = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/sample_submission.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df_train['Num_words_text'] = df_train['text'].apply(lambda x:len(str(x).split())) #Number Of words in main Text in train set"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df_train = df_train[df_train['Num_words_text']>=3]"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["**For Full Understanding of the how to train spacy NER with custom inputs, please read the spacy documentation along with the code presentation in this notebook : https://spacy.io/usage/training#ner Follow along from Updating Spacy NER**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def save_model(output_dir, nlp, new_model_name):\n","    ''' This Function Saves model to \n","    given output directory'''\n","    \n","    output_dir = f'../working/{output_dir}'\n","    if output_dir is not None:        \n","        if not os.path.exists(output_dir):\n","            os.makedirs(output_dir)\n","        nlp.meta[\"name\"] = new_model_name\n","        nlp.to_disk(output_dir)\n","        print(\"Saved model to\", output_dir)"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"trusted":true},"outputs":[],"source":["# pass model = nlp if you want to train on top of existing model \n","\n","def train(train_data, output_dir, n_iter=20, model=None):\n","    \"\"\"Load the model, set up the pipeline and train the entity recognizer.\"\"\"\n","    \"\"\n","    if model is not None:\n","        nlp = spacy.load(output_dir)  # load existing spaCy model\n","        print(\"Loaded model '%s'\" % model)\n","    else:\n","        nlp = spacy.blank(\"en\")  # create blank Language class\n","        print(\"Created blank 'en' model\")\n","    \n","    # create the built-in pipeline components and add them to the pipeline\n","    # nlp.create_pipe works for built-ins that are registered with spaCy\n","    if \"ner\" not in nlp.pipe_names:\n","        ner = nlp.create_pipe(\"ner\")\n","        nlp.add_pipe(ner, last=True)\n","    # otherwise, get it so we can add labels\n","    else:\n","        ner = nlp.get_pipe(\"ner\")\n","    \n","    # add labels\n","    for _, annotations in train_data:\n","        for ent in annotations.get(\"entities\"):\n","            ner.add_label(ent[2])\n","\n","    # get names of other pipes to disable them during training\n","    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"ner\"]\n","    with nlp.disable_pipes(*other_pipes):  # only train NER\n","        # sizes = compounding(1.0, 4.0, 1.001)\n","        # batch up the examples using spaCy's minibatch\n","        if model is None:\n","            nlp.begin_training()\n","        else:\n","            nlp.resume_training()\n","\n","\n","        for itn in tqdm(range(n_iter)):\n","            random.shuffle(train_data)\n","            batches = minibatch(train_data, size=compounding(4.0, 500.0, 1.001))    \n","            losses = {}\n","            for batch in batches:\n","                texts, annotations = zip(*batch)\n","                nlp.update(texts,  # batch of texts\n","                            annotations,  # batch of annotations\n","                            drop=0.5,   # dropout - make it harder to memorise data\n","                            losses=losses, \n","                            )\n","            print(\"Losses\", losses)\n","    save_model(output_dir, nlp, 'st_ner')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def get_model_out_path(sentiment):\n","    '''\n","    Returns Model output path\n","    '''\n","    model_out_path = None\n","    if sentiment == 'positive':\n","        model_out_path = 'models/model_pos'\n","    elif sentiment == 'negative':\n","        model_out_path = 'models/model_neg'\n","    return model_out_path"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def get_training_data(sentiment):\n","    '''\n","    Returns Trainong data in the format needed to train spacy NER\n","    '''\n","    train_data = []\n","    for index, row in df_train.iterrows():\n","        if row.sentiment == sentiment:\n","            selected_text = row.selected_text\n","            text = row.text\n","            start = text.find(selected_text)\n","            end = start + len(selected_text)\n","            train_data.append((text, {\"entities\": [[start, end, 'selected_text']]}))\n","    return train_data"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["#### Training models for Positive and Negative tweets"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-output":true,"trusted":true},"outputs":[],"source":["sentiment = 'positive'\n","\n","train_data = get_training_data(sentiment)\n","model_path = get_model_out_path(sentiment)\n","# For DEmo Purposes I have taken 3 iterations you can train the model as you want\n","train(train_data, model_path, n_iter=3, model=None)"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-output":true,"trusted":true},"outputs":[],"source":["sentiment = 'negative'\n","\n","train_data = get_training_data(sentiment)\n","model_path = get_model_out_path(sentiment)\n","\n","train(train_data, model_path, n_iter=3, model=None)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Predicting with the trained Model"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def predict_entities(text, model):\n","    doc = model(text)\n","    ent_array = []\n","    for ent in doc.ents:\n","        start = text.find(ent.text)\n","        end = start + len(ent.text)\n","        new_int = [start, end, ent.label_]\n","        if new_int not in ent_array:\n","            ent_array.append([start, end, ent.label_])\n","    selected_text = text[ent_array[0][0]: ent_array[0][1]] if len(ent_array) > 0 else text\n","    return selected_text"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["selected_texts = []\n","MODELS_BASE_PATH = '../input/tse-spacy-model/models/'\n","\n","if MODELS_BASE_PATH is not None:\n","    print(\"Loading Models  from \", MODELS_BASE_PATH)\n","    model_pos = spacy.load(MODELS_BASE_PATH + 'model_pos')\n","    model_neg = spacy.load(MODELS_BASE_PATH + 'model_neg')\n","        \n","    for index, row in df_test.iterrows():\n","        text = row.text\n","        output_str = \"\"\n","        if row.sentiment == 'neutral' or len(text.split()) <= 2:\n","            selected_texts.append(text)\n","        elif row.sentiment == 'positive':\n","            selected_texts.append(predict_entities(text, model_pos))\n","        else:\n","            selected_texts.append(predict_entities(text, model_neg))\n","        \n","df_test['selected_text'] = selected_texts"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df_submission['selected_text'] = df_test['selected_text']\n","df_submission.to_csv(\"submission.csv\", index=False)\n","display(df_submission.head(10))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# End Notes\n","Kaggle always provide a lot of days for a competition which one can utilize to learn and grow.As Promised I have presented my first model,along with explanation,you can read spacy's documentation and Rohit singh's kernel as all the code comes from their.If you understand any part of code feel free to comment and ask,I will try to resolve it.\n","As This is my first competition I am also learning along the way ,I will be back with more original ideas and some great more models as I learn more and more about question/answering , different other texhniques , various forms of BERT and Data itself\n","\n","** Thanks for the enormous love and appreciation , I'm Sorry that I have not updated the kernel with Q and A approach,I'm Still learning all the techniques required , will update soon!**\n","<br><br>STAY TUNED!\n","\n","<span style=\"color:Red\"> I hope you Liked my kernel. An upvote is a gesture of appreciation and encouragement that fills me with energy to keep improving my efforts ,be kind to show one ;-)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.0"}},"nbformat":4,"nbformat_minor":4}
